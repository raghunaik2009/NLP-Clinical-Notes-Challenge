{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b07d5a",
   "metadata": {},
   "source": [
    "<h3>Importing Packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ddd7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import wget\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f179c",
   "metadata": {},
   "source": [
    "<h3>Loading input data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5e418b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinnotes = pd.read_csv(\"ClinNotes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2564fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medicalconcept = pd.read_csv(\"MedicalConcepts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afc4281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# BERT Model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased') #, do_lower_case=True, do_basic_tokenize=True\n",
    "model = AutoModel.from_pretrained('bert-large-uncased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5beb79c",
   "metadata": {},
   "source": [
    "<h3>Bert Embedding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d462a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedding():\n",
    "    def __init__(self):\n",
    "        self.tokens = \"\"\n",
    "        self.sentence_tokens = \"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def bert_tokenization(self,text):\n",
    "        # creating text data in required format\n",
    "        marked_text = \"[CLS] \"+ text + \"[ SEP]\"\n",
    "        # spliting the sentence into tokens\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        return tokenized_text\n",
    "\n",
    "    def create_token_mapping(self,tokenized_text):\n",
    "        # mapping the token strings to their vocabulary indeces.\n",
    "        indexed_tokens= tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        # marking each of the 22 tokens as belonging to sentence 1\n",
    "        segments_ids= [1] * len(tokenized_text)\n",
    "\n",
    "        #converting inputs to pytorch tensors\n",
    "        tokens_tensor= torch.tensor([indexed_tokens])\n",
    "        segments_tensors= torch.tensor([segments_ids])\n",
    "        # putting the model in evaluaion mode\n",
    "        model.eval()\n",
    "\n",
    "        # running the text through Bert, and collecting all of the hidden states produced by the layers.\n",
    "        with torch.no_grad():\n",
    "            outputs=model(tokens_tensor,segments_tensors)\n",
    "            hidden_states=outputs[2]\n",
    "\n",
    "        return hidden_states  \n",
    "\n",
    "    def get_word_vector(self,text):\n",
    "        tokenized_text = self.bert_tokenization(text)\n",
    "\n",
    "        hidden_states = self.create_token_mapping(tokenized_text)\n",
    "        # combining the layers to making one big vector\n",
    "        token_embeddings= torch.stack(hidden_states,dim=0) \n",
    "\n",
    "        # Removing dimension 1 from the batches.\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "        # Swaping the dimensions 0 and 1.\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)  \n",
    "\n",
    "\n",
    "        token_vecs_sum = []\n",
    "\n",
    "        for token in token_embeddings:\n",
    "            # token is a [12 x 768] tensor\n",
    "            # Sum the vectors from the last four layers.\n",
    "            sum_vec = torch.sum(token[-4:], dim=0)\n",
    "            # appending the vectors values in dict\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "\n",
    "        #calculating the mean of the tensor\n",
    "        mean = torch.mean(torch.stack(token_vecs_sum),dim=-2)\n",
    "        # converting tensor to numpy array\n",
    "        mean = mean.detach().numpy()\n",
    "        return mean\n",
    "\n",
    "    def get_sentence_vector(self,text):\n",
    "        marked_text = \"[CLS] \"+ text + \"[ SEP]\"\n",
    "        tokenized_text = self.bert_tokenization(text)[:512]\n",
    "        hidden_states = self.create_token_mapping(tokenized_text)\n",
    "        # token_vecs is a tensor with shape [22 x 768]\n",
    "        token_vecs = hidden_states[-2][0]\n",
    "        # Calculating the average of all token vectors.\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        # converting the tensor to numpy array\n",
    "        sentence_embedding=sentence_embedding.detach().numpy()\n",
    "        return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8aa2754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating word vector for single word\n",
    "text = \"Glaucoma\"\n",
    "bert_model = BERTEmbedding()\n",
    "word_vector = bert_model.get_word_vector(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06ff3287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5140185 , -2.6454067 , -0.87413967, ...,  2.1172893 ,\n",
       "        2.8381119 ,  3.6507912 ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "915c6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the word vector of the all the terms\n",
    "df_medicalconcept['bert_embedding_term1'] = df_medicalconcept['Term1'].apply(lambda x: bert_model.get_word_vector(x))\n",
    "df_medicalconcept['bert_embedding_term2'] = df_medicalconcept['Term2'].apply(lambda x: bert_model.get_word_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e3a2caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "      <th>bert_embedding_term1</th>\n",
       "      <th>bert_embedding_term2</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>Fibrillation</td>\n",
       "      <td>[-3.5140185, -2.6454067, -0.87413967, -0.46554...</td>\n",
       "      <td>[-2.7083907, -3.4811642, -0.7629569, 1.0560955...</td>\n",
       "      <td>0.871441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carbatrol</td>\n",
       "      <td>Dilantin</td>\n",
       "      <td>[-2.6614735, -2.0590873, -1.7914397, 0.6470068...</td>\n",
       "      <td>[-2.532657, -2.9835286, -1.5824735, 0.15296777...</td>\n",
       "      <td>0.812776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardiomyopathy</td>\n",
       "      <td>Tylenol</td>\n",
       "      <td>[-3.0159822, -2.0221212, -2.9911427, -0.695508...</td>\n",
       "      <td>[-3.628576, -2.5959907, -1.3957688, 0.08992670...</td>\n",
       "      <td>0.817618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herpes</td>\n",
       "      <td>Hyperthyroidism</td>\n",
       "      <td>[-2.78776, -2.5111175, -1.7512555, 0.33207077,...</td>\n",
       "      <td>[-2.3670392, -2.159456, -2.382085, -0.59684986...</td>\n",
       "      <td>0.790684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seasickness</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>[-2.5917146, -3.334326, -2.1953273, 0.9285096,...</td>\n",
       "      <td>[-2.1828365, -2.234159, -2.4591382, 1.6850199,...</td>\n",
       "      <td>0.782326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term1            Term2  \\\n",
       "0        Glaucoma     Fibrillation   \n",
       "1       Carbatrol         Dilantin   \n",
       "2  Cardiomyopathy          Tylenol   \n",
       "3          Herpes  Hyperthyroidism   \n",
       "4     Seasickness           Nausea   \n",
       "\n",
       "                                bert_embedding_term1  \\\n",
       "0  [-3.5140185, -2.6454067, -0.87413967, -0.46554...   \n",
       "1  [-2.6614735, -2.0590873, -1.7914397, 0.6470068...   \n",
       "2  [-3.0159822, -2.0221212, -2.9911427, -0.695508...   \n",
       "3  [-2.78776, -2.5111175, -1.7512555, 0.33207077,...   \n",
       "4  [-2.5917146, -3.334326, -2.1953273, 0.9285096,...   \n",
       "\n",
       "                                bert_embedding_term2  cosine_similarity  \n",
       "0  [-2.7083907, -3.4811642, -0.7629569, 1.0560955...           0.871441  \n",
       "1  [-2.532657, -2.9835286, -1.5824735, 0.15296777...           0.812776  \n",
       "2  [-3.628576, -2.5959907, -1.3957688, 0.08992670...           0.817618  \n",
       "3  [-2.3670392, -2.159456, -2.382085, -0.59684986...           0.790684  \n",
       "4  [-2.1828365, -2.234159, -2.4591382, 1.6850199,...           0.782326  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medicalconcept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8b086ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medicalconcept['cosine_similarity'] = df_medicalconcept.apply(lambda x: 1 - spatial.distance.cosine(x['bert_embedding_term1'], x['bert_embedding_term2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5eaf0f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term1</th>\n",
       "      <th>Term2</th>\n",
       "      <th>bert_embedding_term1</th>\n",
       "      <th>bert_embedding_term2</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Glaucoma</td>\n",
       "      <td>Fibrillation</td>\n",
       "      <td>[-3.5140185, -2.6454067, -0.87413967, -0.46554...</td>\n",
       "      <td>[-2.7083907, -3.4811642, -0.7629569, 1.0560955...</td>\n",
       "      <td>0.894104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carbatrol</td>\n",
       "      <td>Dilantin</td>\n",
       "      <td>[-2.6614735, -2.0590873, -1.7914397, 0.6470068...</td>\n",
       "      <td>[-2.532657, -2.9835286, -1.5824735, 0.15296777...</td>\n",
       "      <td>0.921481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardiomyopathy</td>\n",
       "      <td>Tylenol</td>\n",
       "      <td>[-3.0159822, -2.0221212, -2.9911427, -0.695508...</td>\n",
       "      <td>[-3.628576, -2.5959907, -1.3957688, 0.08992670...</td>\n",
       "      <td>0.879889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Herpes</td>\n",
       "      <td>Hyperthyroidism</td>\n",
       "      <td>[-2.78776, -2.5111175, -1.7512555, 0.33207077,...</td>\n",
       "      <td>[-2.3670392, -2.159456, -2.382085, -0.59684986...</td>\n",
       "      <td>0.883667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seasickness</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>[-2.5917146, -3.334326, -2.1953273, 0.9285096,...</td>\n",
       "      <td>[-2.1828365, -2.234159, -2.4591382, 1.6850199,...</td>\n",
       "      <td>0.844041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Term1            Term2  \\\n",
       "0        Glaucoma     Fibrillation   \n",
       "1       Carbatrol         Dilantin   \n",
       "2  Cardiomyopathy          Tylenol   \n",
       "3          Herpes  Hyperthyroidism   \n",
       "4     Seasickness           Nausea   \n",
       "\n",
       "                                bert_embedding_term1  \\\n",
       "0  [-3.5140185, -2.6454067, -0.87413967, -0.46554...   \n",
       "1  [-2.6614735, -2.0590873, -1.7914397, 0.6470068...   \n",
       "2  [-3.0159822, -2.0221212, -2.9911427, -0.695508...   \n",
       "3  [-2.78776, -2.5111175, -1.7512555, 0.33207077,...   \n",
       "4  [-2.5917146, -3.334326, -2.1953273, 0.9285096,...   \n",
       "\n",
       "                                bert_embedding_term2  cosine_similarity  \n",
       "0  [-2.7083907, -3.4811642, -0.7629569, 1.0560955...           0.894104  \n",
       "1  [-2.532657, -2.9835286, -1.5824735, 0.15296777...           0.921481  \n",
       "2  [-3.628576, -2.5959907, -1.3957688, 0.08992670...           0.879889  \n",
       "3  [-2.3670392, -2.159456, -2.382085, -0.59684986...           0.883667  \n",
       "4  [-2.1828365, -2.234159, -2.4591382, 1.6850199,...           0.844041  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medicalconcept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04c9f1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8335796176018226"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medicalconcept['cosine_similarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f18d0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medicalconcept.to_csv(\"medical_concept_similarity_bert_large.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c8f24",
   "metadata": {},
   "source": [
    "<h3>Clean Text</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d37d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "#removing stop words\n",
    "df_clinnotes['clean_notes'] = df_clinnotes['notes'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in (stop_words)]))\n",
    "#removing puntuation\n",
    "df_clinnotes[\"clean_notes\"] = df_clinnotes['clean_notes'].str.replace('[^\\w\\s]','', regex=True)\n",
    "#lemetizing the text\n",
    "w_tokenizer = WhitespaceTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "df_clinnotes['clean_notes'] = df_clinnotes['clean_notes'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "580c94c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#get sentence vector for all notes\n",
    "df_clinnotes['sentence_embedding'] = df_clinnotes['clean_notes'].apply(lambda x: bert_model.get_sentence_vector(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71191e04",
   "metadata": {},
   "source": [
    "<h3>Splitting Training and Test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68292268",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_clinnotes.sentence_embedding, df_clinnotes.category, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a5e986d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fc803",
   "metadata": {},
   "source": [
    "<h3>Performing Cross Validation on Various ML Algorithms</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "775bc858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=500, random_state=42, min_samples_split=3, min_samples_leaf=2),\n",
    "    LinearSVC(),\n",
    "    XGBClassifier(learning_rate =0.07,n_estimators=100),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, np.array(X_train.tolist()), y_train, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "099f4042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.679389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.610687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.687023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.748092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>2</td>\n",
       "      <td>0.824427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>3</td>\n",
       "      <td>0.801527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>4</td>\n",
       "      <td>0.830769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.763359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.633588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.610687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.740458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0.623077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name  fold_idx  accuracy\n",
       "0   RandomForestClassifier         0  0.679389\n",
       "1   RandomForestClassifier         1  0.641221\n",
       "2   RandomForestClassifier         2  0.610687\n",
       "3   RandomForestClassifier         3  0.687023\n",
       "4   RandomForestClassifier         4  0.653846\n",
       "5                LinearSVC         0  0.816794\n",
       "6                LinearSVC         1  0.748092\n",
       "7                LinearSVC         2  0.824427\n",
       "8                LinearSVC         3  0.801527\n",
       "9                LinearSVC         4  0.830769\n",
       "10           XGBClassifier         0  0.763359\n",
       "11           XGBClassifier         1  0.633588\n",
       "12           XGBClassifier         2  0.610687\n",
       "13           XGBClassifier         3  0.740458\n",
       "14           XGBClassifier         4  0.623077"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c3de7",
   "metadata": {},
   "source": [
    "<h3>Plotting Cross Validation result</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f239f46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a2c72",
   "metadata": {},
   "source": [
    "<h3>Evaluating various models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "863642bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.39%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           Cardiovascular / Pulmonary  Gastroenterology   Neurology  accuracy  \\\n",
      "precision                    0.989933          1.000000    0.994413  0.993884   \n",
      "recall                       1.000000          0.983333    0.994413  0.993884   \n",
      "f1-score                     0.994941          0.991597    0.994413  0.993884   \n",
      "support                    295.000000        180.000000  179.000000  0.993884   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.994782      0.993930  \n",
      "recall       0.992582      0.993884  \n",
      "f1-score     0.993650      0.993876  \n",
      "support    654.000000    654.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[295   0   0]\n",
      " [  2 177   1]\n",
      " [  1   0 178]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 58.54%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           Cardiovascular / Pulmonary  Gastroenterology  Neurology  accuracy  \\\n",
      "precision                    0.571429          0.545455   0.666667  0.585366   \n",
      "recall                       0.736842          0.409091   0.500000  0.585366   \n",
      "f1-score                     0.643678          0.467532   0.571429  0.585366   \n",
      "support                     76.000000         44.000000  44.000000  0.585366   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.594517      0.590012  \n",
      "recall       0.548644      0.585366  \n",
      "f1-score     0.560880      0.577036  \n",
      "support    164.000000    164.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[56 11  9]\n",
      " [24 18  2]\n",
      " [18  4 22]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=500, random_state=42, min_samples_split=3, min_samples_leaf=2, )\n",
    "rf_clf.fit(np.array(X_train.tolist()), y_train)\n",
    "print_score(rf_clf, np.array(X_train.tolist()), y_train, np.array(X_test.tolist()), y_test, train=True)\n",
    "print_score(rf_clf, np.array(X_train.tolist()), y_train, np.array(X_test.tolist()), y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07269675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.39%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           Cardiovascular / Pulmonary  Gastroenterology   Neurology  accuracy  \\\n",
      "precision                    0.993243          0.994413    0.994413  0.993884   \n",
      "recall                       0.996610          0.988889    0.994413  0.993884   \n",
      "f1-score                     0.994924          0.991643    0.994413  0.993884   \n",
      "support                    295.000000        180.000000  179.000000  0.993884   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.994023      0.993886  \n",
      "recall       0.993304      0.993884  \n",
      "f1-score     0.993660      0.993881  \n",
      "support    654.000000    654.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[294   1   0]\n",
      " [  1 178   1]\n",
      " [  1   0 178]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 72.56%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           Cardiovascular / Pulmonary  Gastroenterology  Neurology  accuracy  \\\n",
      "precision                    0.788732          0.688889   0.666667   0.72561   \n",
      "recall                       0.736842          0.704545   0.727273   0.72561   \n",
      "f1-score                     0.761905          0.696629   0.695652   0.72561   \n",
      "support                     76.000000         44.000000  44.000000   0.72561   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.714763      0.729196  \n",
      "recall       0.722887      0.725610  \n",
      "f1-score     0.718062      0.726617  \n",
      "support    164.000000    164.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[56  9 11]\n",
      " [ 8 31  5]\n",
      " [ 7  5 32]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "lsvc_clf = LinearSVC(C=1.0) #n_jobs=4,\n",
    "lsvc_clf.fit(np.array(X_train.tolist()), y_train)\n",
    "print_score(lsvc_clf, np.array(X_train.tolist()), y_train, np.array(X_test.tolist()), y_test, train=True)\n",
    "print_score(lsvc_clf, np.array(X_train.tolist()), y_train, np.array(X_test.tolist()), y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4df6cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghu/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:28:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"enable_categorical\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:28:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.39%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           Cardiovascular / Pulmonary  Gastroenterology   Neurology  accuracy  \\\n",
      "precision                    0.989933          0.994413    1.000000  0.993884   \n",
      "recall                       1.000000          0.988889    0.988827  0.993884   \n",
      "f1-score                     0.994941          0.991643    0.994382  0.993884   \n",
      "support                    295.000000        180.000000  179.000000  0.993884   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.994782      0.993921  \n",
      "recall       0.992572      0.993884  \n",
      "f1-score     0.993655      0.993880  \n",
      "support    654.000000    654.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[295   0   0]\n",
      " [  2 178   0]\n",
      " [  1   1 177]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 66.46%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           Cardiovascular / Pulmonary  Gastroenterology  Neurology  accuracy  \\\n",
      "precision                    0.658824          0.590909   0.771429  0.664634   \n",
      "recall                       0.736842          0.590909   0.613636  0.664634   \n",
      "f1-score                     0.695652          0.590909   0.683544  0.664634   \n",
      "support                     76.000000         44.000000  44.000000  0.664634   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.673720      0.670814  \n",
      "recall       0.647129      0.664634  \n",
      "f1-score     0.656702      0.664302  \n",
      "support    164.000000    164.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[56 12  8]\n",
      " [18 26  0]\n",
      " [11  6 27]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=100, enable_categorical=True) #n_jobs=4,\n",
    "xgb_clf.fit(np.array(X_train.tolist()), y_train)\n",
    "print_score(xgb_clf, np.array(X_train.tolist()), y_train, np.array(X_test.tolist()), y_test, train=True)\n",
    "print_score(xgb_clf, np.array(X_train.tolist()), y_train, np.array(X_test.tolist()), y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746464f",
   "metadata": {},
   "source": [
    "<h3>Results</h3>\n",
    "1. Vector representation for all the medical concepts words generated using Pretrained Bio Bert. <br>\n",
    "2. Resulted embedded vector used for Clinical notes classification. Performance is lower as compare to Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df81921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f028ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
